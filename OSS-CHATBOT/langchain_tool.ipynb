{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d24db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1) .env ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "\n",
    "# 2) LangChainìš© LLM ê°ì²´ ë§Œë“¤ê¸° (Azure OpenAI v1 ë°©ì‹)\n",
    "model = ChatOpenAI(\n",
    "    model=os.getenv(\"DEPLOYMENT_NAME\"),               \n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),            \n",
    "    base_url=os.getenv(\"ENDPOINT_URL\").rstrip(\"/\") + \"/openai/v1/\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf85af72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” í˜„ì¬ ì‹œê°„ì„ ì§ì ‘ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  \\nì œê°€ ì‚¬ìš©í•˜ëŠ” ì‹œìŠ¤í…œì—ì„œëŠ” ì‹¤ì‹œê°„ ì‹œê³„ ê¸°ëŠ¥ì´ ì—†ì–´ì„œ, í˜„ì¬ ì‹œê°„ì„ ì•Œë ¤ë“œë¦´ ìˆ˜ ì—†ì–´ìš”.  \\ní˜¹ì‹œ ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 20, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_f99638a8d7', 'id': 'chatcmpl-Ce56HrNL5hG9WZH3xZnSo0QDGzjak', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--763f3bfa-e53e-4f36-bf4f-b568a606b746-0', usage_metadata={'input_tokens': 20, 'output_tokens': 47, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(\"ì˜ ì§€ëƒˆì–´? ì§€ê¸ˆ í˜„ì¬ ì‹œê°„ì´ ëª‡ì‹œì•¼? \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from datetime import datetime\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a85c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time(timezone: str, location: str) -> str:\n",
    "    \"\"\" í˜„ì¬ ì‹œê°„ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "    timezone (str): íƒ€ì„ì¡´(ì˜ˆ: 'Asia/Seoul'). ì‹¤ì œ ì¡´ì¬í•´ì•¼ í•¨\n",
    "    location (str): ì§€ì—­ëª…. íƒ€ì„ì¡´ì€ ëª¨ë“  ì§€ëª…ì— ëŒ€ì‘ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì´í›„ modle ë‹µë³€ ìƒì„±ì— ì‚¬ìš©ë¨\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    tz = pytz.timezone(timezone)\n",
    "\n",
    "    now = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    location_and_local_time = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'\n",
    "    print(location_and_local_time)\n",
    "    \n",
    "    return location_and_local_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87355b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_current_time,]\n",
    "tool_dict = {\"get_current_time\": get_current_time, }\n",
    "\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8788fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë„ˆëŠ” ì‚¬ìš©ì ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ Toolì„ ì‚¬ìš©í•  ê±°ì•¼', additional_kwargs={}, response_metadata={}), HumanMessage(content='íŒŒë¦¬ëŠ” ì§€ê¸ˆ ëª‡ ì‹œì•¼?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 124, 'total_tokens': 146, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_f99638a8d7', 'id': 'chatcmpl-Ce57L7VeeyloAJUmoWGkjXleamBFc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3018f7d5-8657-4e57-a193-73e36b90497b-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Europe/Paris', 'location': 'Paris'}, 'id': 'call_vyq8AUKzN3iGZYwkYOM8vYH4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 124, 'output_tokens': 22, 'total_tokens': 146, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"ë„ˆëŠ” ì‚¬ìš©ì ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ Toolì„ ì‚¬ìš©í•  ê±°ì•¼\"),\n",
    "    HumanMessage(\"íŒŒë¦¬ëŠ” ì§€ê¸ˆ ëª‡ ì‹œì•¼?\"),\n",
    "]\n",
    "\n",
    "response = model_with_tools.invoke(messages)\n",
    "messages.append(response)\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c33a6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timezone': 'Europe/Paris', 'location': 'Paris'}\n",
      "Europe/Paris (Paris) í˜„ì¬ì‹œê° 2025-11-20 21:00:30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ë„ˆëŠ” ì‚¬ìš©ì ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ Toolì„ ì‚¬ìš©í•  ê±°ì•¼', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='íŒŒë¦¬ëŠ” ì§€ê¸ˆ ëª‡ ì‹œì•¼?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 124, 'total_tokens': 146, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_f99638a8d7', 'id': 'chatcmpl-Ce57L7VeeyloAJUmoWGkjXleamBFc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3018f7d5-8657-4e57-a193-73e36b90497b-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Europe/Paris', 'location': 'Paris'}, 'id': 'call_vyq8AUKzN3iGZYwkYOM8vYH4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 124, 'output_tokens': 22, 'total_tokens': 146, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Europe/Paris (Paris) í˜„ì¬ì‹œê° 2025-11-20 21:00:30', name='get_current_time', tool_call_id='call_vyq8AUKzN3iGZYwkYOM8vYH4')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = tool_dict[tool_call[\"name\"]]\n",
    "    print(tool_call[\"args\"])\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e4e1cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='íŒŒë¦¬ì˜ í˜„ì¬ ì‹œê°ì€ 2025ë…„ 11ì›” 20ì¼ 21ì‹œ 00ë¶„ 30ì´ˆì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 176, 'total_tokens': 206, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_f99638a8d7', 'id': 'chatcmpl-Ce57Q5zmztQ6OxZV75sJhVkqfwfbE', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--db92e7eb-b450-49fb-9139-15453a51cfae-0', usage_metadata={'input_tokens': 176, 'output_tokens': 30, 'total_tokens': 206, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a66ba8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ì˜ ì§€ëƒˆì–´ìš”. ğŸ˜Š  \n",
      "ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´(Open Source Software, OSS)ì— ëŒ€í•´ ì„¤ëª…í•´ë“œë¦´ê²Œìš”.\n",
      "\n",
      "**ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ë€?**  \n",
      "ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ì†ŒìŠ¤ ì½”ë“œê°€ ê³µê°œë˜ì–´ ëˆ„êµ¬ë‚˜ ììœ ë¡­ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , ìˆ˜ì •í•˜ê±°ë‚˜ ë°°í¬í•  ìˆ˜ ìˆëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ë§í•©ë‹ˆë‹¤. ì¦‰, ì†Œí”„íŠ¸ì›¨ì–´ì˜ ì„¤ê³„ë„(ì†ŒìŠ¤ ì½”ë“œ)ê°€ ê³µê°œë˜ì–´ ìˆì–´ì„œ ê°œë°œìë‚˜ ì‚¬ìš©ìê°€ ììœ ë¡­ê²Œ ì ‘ê·¼í•˜ê³ , í•„ìš”ì— ë”°ë¼ ê°œì„ í•˜ê±°ë‚˜ ê¸°ëŠ¥ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ì£¼ìš” íŠ¹ì§•**\n",
      "- **ì†ŒìŠ¤ ì½”ë“œ ê³µê°œ**: ëˆ„êµ¬ë‚˜ ì†ŒìŠ¤ ì½”ë“œë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ììœ ë¡œìš´ ì‚¬ìš©**: ê°œì¸, ê¸°ì—… ë“± ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ìˆ˜ì • ë° ë°°í¬ ê°€ëŠ¥**: ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜, ìˆ˜ì •í•œ ë²„ì „ì„ ë‹¤ì‹œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "- **ë¼ì´ì„ ìŠ¤**: ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ë³´í†µ GPL, MIT, Apache ë“±ê³¼ ê°™ì€ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ê° ë¼ì´ì„ ìŠ¤ë§ˆë‹¤ ì‚¬ìš©, ìˆ˜ì •, ë°°í¬ ì¡°ê±´ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ëŒ€í‘œì ì¸ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ì˜ˆì‹œ**\n",
      "- **ë¦¬ëˆ…ìŠ¤(Linux)**: ëŒ€í‘œì ì¸ ì˜¤í”ˆì†ŒìŠ¤ ìš´ì˜ì²´ì œ\n",
      "- **ì•„íŒŒì¹˜(Apache)**: ì›¹ ì„œë²„ ì†Œí”„íŠ¸ì›¨ì–´\n",
      "- **íŒŒì´ì¬(Python)**: í”„ë¡œê·¸ë˜ë° ì–¸ì–´\n",
      "- **íŒŒì´ì–´í­ìŠ¤(Firefox)**: ì›¹ ë¸Œë¼ìš°ì €\n",
      "\n",
      "**ì¥ì **\n",
      "- ë¹„ìš© ì ˆê°(ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥)\n",
      "- ì»¤ë®¤ë‹ˆí‹°ì˜ í™œë°œí•œ ì§€ì›ê³¼ ë¹ ë¥¸ ë²„ê·¸ ìˆ˜ì •\n",
      "- ë‹¤ì–‘í•œ ê¸°ëŠ¥ ì¶”ê°€ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥\n",
      "\n",
      "**ë‹¨ì **\n",
      "- ê³µì‹ì ì¸ ì§€ì›ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ\n",
      "- ì‚¬ìš© ë° ë°°í¬ ì‹œ ë¼ì´ì„ ìŠ¤ ì¡°ê±´ì„ ì˜ í™•ì¸í•´ì•¼ í•¨\n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"
     ]
    }
   ],
   "source": [
    "for c in model.stream([HumanMessage(\"ì˜ ì§€ëƒˆì–´? ì˜¤í”ˆì†ŒìŠ¤SWì— ëŒ€í•´ì„œ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•´ì¤˜\")]):\n",
    "    print(c.content, end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
